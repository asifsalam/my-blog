---
pre_title: 'Building the Data-Driven Enterprise'
title: Part 1 - Why Data & AI initiatives Fail
sub_title: ''
preview_image: ''
author: Asif Salam
id: 'L02229'
published: true
post_date: '2023-11-29'
excerpt: 'Compelled by two powerful narratives – the promise of efficiency and automation, and the fear of competitors accelerating away – companies have invested heavily in efforts to become “data-driven” over the last couple of decades. The term, a staple on annual reports and in all staff meetings, is as nebulous as a horoscope.  And yet, despite executive ambitions, massive investments and the bags of good intentions, tangible benefits remain elusive for many.'
categories:
  - 'post'
  - 'my-post'
  - 'opinion'
  - 'general'
  - 'data-driven-enterprise'
  - 'peril'
  - 'pitfall'
---

## Introduction

Compelled by two powerful narratives – the promise of efficiency and automation, and the fear of competitors accelerating away – companies have invested heavily in efforts to become “data-driven” over the last couple of decades. The term, a staple on annual reports and in all staff meetings, is as nebulous as a horoscope. And yet, despite executive ambitions, massive investments and the bags of good intentions, tangible benefits remain elusive for many.

It is no secret that most data & AI initiatives fail. Industry articles and experts estimate failure rates between 70% and 85% (see 1,2,3,5,6,8 in the [References](#references) section below) indicating quite a gulf between desire and ability to execute. But the allure of data and AI providing easy solutions to long standing business problems is powerful. Instead, organizations often find themselves burdened with the costs of a bewildering array of tools and platforms, scattered data assets, and a long tail of underutilized solutions. And the pressure to deliver continues to mount with new waves of advancement and hype.

Why do so many companies struggle to get data right? Reliable research in this area is hard to conduct, given the complexity of organizational dynamics and constant change. Most articles and reports are based on survey data. These surveys, and the resulting reports, usually target senior executives and provide a polished, abstract picture that is does not fully reflect the realities faced by those implementing these initiatives on the ground. The reference section at the bottom contains links to some of these articles\*.

While the executive viewpoint is relevant, the perspectives of those that drive and participate in these efforts play a vital role in identifying and addressing challenges. Their experiences and perceptions can offer valuable, first-hand insights and highlight practical hurdles, often missing from high-level reports. This is my take, based on work on many such initiatives over the last decade, on where things go wrong, and how to improve the odds of success.

_(\*Edit: A few recent reports do cast a wider net. The ones by the RAND National Security Research Division [10] and sthe Centre for Business Analytics at the Melbourne School of Business [9] are quite good, offering useful analysis and insights based on a broader range of respondents and data sources.)_

Let’s start with the pitfalls.

## Why data and AI initiatives fail

Success doesn’t come with a guarantee of course, but here is my list of 10 missteps that indicate that your organization has some work to do to get this data-driven thing right.

### 1. Short term wins, long-term failure

This is when executives want to build capability incrementally, with the idea that value must be demonstrated one use-case at a time. Frontline staff are asked to come up with ideas with potential. A few of these are selected for implementation, with progress reported regularly. This bottom-up, scattered approach allows executives to push down accountability and focus on short term results, while positioning data and AI as key areas. But without a broader strategic, long-term vision, this approach leads to disjointed efforts. These one-off projects do not scale or align with broader business goals and fail to deliver any kind of sustained impact.

A companion to this approach is the focus on “quick wins,” where the assumption is that data can be used to deliver returns quickly. The pressure to show results means that everything is rushed. With vague requirements, unrealistic timelines, limited competence, resources and funding, the promised returns rarely materialize. And when they don’t, executive interest fades, and funding is pulled. The reality is that it takes long term vision, careful planning, and sustained efforts to achieve some successes. But the allure of data and AI providing easy solutions to long standing issues is powerful.

### 2. Reporting & control mindset

Some organizations treat data primarily as a mechanism for reporting and control, tracking progress, and managing performance. The data comes from various operational systems, but is also self-reported and manually collected, with significant adjustment and manual processing before the results are presented. But when the priority is compliance and governance, organizations fail to capture the potential for innovation, decision-making and automation.

### 3. Fear of data

Used appropriately, data can provide transparency, insight, and in certain areas, an element of foresight. While data can sometimes provide answers, some executives can view this as a loss of authority, fearing the exposure of poor performance. Companies can also use data as a way of fostering competition between units and individuals. When data is tied to rewards and punishment, it becomes something to game the metrics, incentivizing unintended behaviours. The veneer of objectivity associated with data can be hard to counter.

### 4. Politics

Data can be of great value, but when data is on the corporate agenda as a buzzword, executives battle over control of data and who gets to own the narrative and limelight. Those that lead functions and units, fight to keep data within their control. Conflict and competing agendas within the executive team cause fragmentation and misalignment and usually derail the efforts.

### 5. Scattered responsibility

It is often unclear who is responsible for data within the organization, or what ”responsibility for data” entails. This means that no one is fully accountable for ensuring data created in the company is usable by others. Each unit does things in their own way, with their own standards, definitions, tools and platforms. This of course creates data islands and limits data interoperability. But it also makes it almost impossible to succeed with cross-functional reporting and automation efforts, requiring alignment of conflicting data and extensive, time-consuming manual manipulation, undermining trust in the data and analysis.

### 6. IT &#151 The accidental gatekeeper

When data is not considered a strategic issue, assigning clear data ownership and responsibilities can seem unimportant. Whether by omission or just an inability to decide, IT steps in to fill the gap, because they need clarity in order to build applications. This may appear reasonable given IT’s role in managing technical aspects such as platforms, technology, architecture, tools, and security. It is only logical that data is then managed as a component of application development and operations, managed as an IT asset, with a focus on platforms and security, rather than a strategic asset essential for analytics, insight, automation and prediction.

### 7. Underestimating the complexity

Working with data is easy. In Excel. But putting in place the systems and structures to create the foundation for making a company data-driven is another matter. Getting it working across functional and unit boundaries, processes, applications, variety of users and usage scenarios from analytics to automation to prediction is complex. It requires long term thinking, with thoughtful and consistent work on alignment, standardization, supporting systems and structures, long term investments in platforms and technology, competence and skills.

### 8. Focus on tools & technology

Data is an integral part of the modern enterprise. All companies provide their managers and analysts with applications for reporting and analysis based on their roles and tasks. Over time they end up with a disparate collection of platforms and applications that don’t work together. But when a company decides it is time to become data driven, a long list of current problems is created - quality, access, proliferation of ungoverned data stores, duplication, poor alignment and interoperability and so on. Companies turn to technology vendors to help solve these issues. The reasons are fairly straightforward, I think. There is something comforting about a crisp business case, with clear costs and value, a signed contract and clear accountability. There are also political benefits to owning the associated budget and resources. Of course, this does not address the underlying causes, which are often structural, requiring long term, cross functional efforts with limited short term benefits. It is much easier to give money to someone.

Since data is closely connected to applications and platforms used in an enterprise, companies quickly focus on technology to solve these issues. A standard data warehouse, a data quality tool, a data catalog and so on - tangible applications, with negotiable license costs and a vendor to hold responsible. This enables the organization to assign a financial value to the effort, as estimating the actual value of the data a company owns is an impossible task. Of course the tools and technology rarely fix the underlying causes of the issues, which are often structural.

Platforms, tools and technology should fit strategic objectives and business needs.

### 9 Lack of proper data literacy

This, in my opinion, is the most significant issue, and one that is consistently overlooked in the discussion around making companies “data-driven”. Data literacy programs, often a low priority for organizations, lack strategic focus and direction. They typically consist of a set of off-the shelf courses foisted on operational staff, something to check-off on the training path for a set of roles. However, data literacy programs should be aligned to the business goals and strategic objectives of the organization, tailored to the various roles. A very specific data literacy program for leadership and management is an essential component of a broader data literacy program. Their roles demand an understanding tailored to the strategic value of data. They don’t need to be technical experts, but they must understand those aspects that allow them to set realistic expectations around data, assess initiatives, priortize investments, allocate resources, monitor and direct progress.

## Next

The journey to becoming data-driven often begins with bold ambitions, but the path is riddled with obstacles, dead ends, detours and missing sections. Companies often fall into predictable traps. Long term success with data and AI requires strategic alignment, sustained investment, and a commitment to long-term change - there are few shortcuts or quick fixes. In the next post, I will outline a structured approach, that I think can help organizations address these challenges and improve their chances of success in building a data-driven, AI-enabled enterprise. Unsurprisingly, it starts at the top.

## References

<a id="references"></a>

1. Brian T. O'Neill, Failure rates for analytics, AI, and big data projects = 85% – yikes!, 23 July, 2019, Design for Analytics, [(link)](https://designingforanalytics.com/resources/failure-rates-for-analytics-bi-iot-and-big-data-projects-85-yikes/).
2. Mayur P. Joshi et al., Why So Many Data Science Projects Fail to Deliver, 02 March, 2021, MIT Sloan Management Review, [(link)](https://sloanreview.mit.edu/article/why-so-many-data-science-projects-fail-to-deliver/).
3. Jeremy Kahn, Want your company’s A.I. project to succeed? Don’t hand it to the data scientists, says this CEO, 26 July, 2022, Fortune Magazine, [(link)](https://fortune.com/2022/07/26/a-i-success-business-sense-aible-sengupta/).
4. Michael Chui et al., The state of AI in 2022 - and a half decade in review, December, 2022, McKinsey and Company, [(link)](https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai-in-2022-and-a-half-decade-in-review).
5. Randy Bean & Allison Sagraves, Why Chief Data and AI Officers Are Set Up to Fail, Harvard Business Review, June 20, 2023, [(link)](https://hbr.org/2023/06/why-chief-data-and-ai-officers-are-set-up-to-fail).
6. Deborshi Dutt et al., Insights fromt he leading edge of generative AI adoption, Deloitte's State of Generative AI in the Enterprise, Quarter one report, January 2024, [(link)](https://www2.deloitte.com/content/dam/Deloitte/us/Documents/consulting/us-state-of-gen-ai-report.pdf)
7. Gartner, Gartner Predicts 80% of D&A Governance Initiatives Will Fail by 2027, 28 February, 2024, Gartner, [(link)](https://www.gartner.com/en/newsroom/press-releases/2024-02-28-gartner-predicts-80-percent-of-data-and-analytics-governance-initiatives-will-fail-by-2027-due-to-a-lack-of-a-real-or-manufactured-crisis-).
8. Aasheesh Mittal et al., Revolutionalizing procurement: Leveraging data and AI for strategic advantage, 13 June, 2024, McKinsey and Company, [(link)](https://www.mckinsey.com/capabilities/operations/our-insights/revolutionizing-procurement-leveraging-data-and-ai-for-strategic-advantage).
9. Isaac Sacolick, 7 reasons analytics and ML fail to meet business objectives (survey of business leaders), 15 July, 2024, Infoworld, [(link)](https://www.infoworld.com/article/2515702/7-reasons-analytics-and-ml-fail-to-meet-business-objectives.html).
10. Dr. Evan Shellshear, Why do analytics and AI projects fail?, 09 August, 2024, Center for Business Analytics, Melbourne School of Business,
    [(link)](https://mbs.edu/centres/centre-for-business-analytics/research/why-do-analytics-and-ai-projects-fail).
11. James Ryseff et al., The Root Causes of Failure for Artificial Intelligence Projects and How They Can Succeed, 13 August, 2024, RAND National Security Research Division, [(link)](https://www.rand.org/pubs/research_reports/RRA2680-1.html).

### Coming eventually:

- Part 2 &#151 How to get data & AI right - an approach
